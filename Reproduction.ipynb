{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction: Planning in Dynamic Environments with Conditional Autoregressive Models\n",
    "\n",
    "**Abhinav Madahar (<abhinav.madahar@rutgers.edu>) &middot; Sungjin Ahn**\n",
    "\n",
    "Todo:\n",
    "\n",
    "- [x] Movement about the environment is continuous, but collision and goal checking is quantized to the nearest pixel.\n",
    "- [x] The agent (controlled by the model) is a $1 \\times 1$ object and the goal is $2 \\times 2$.\n",
    "- [x] Both are randomly placed.\n",
    "- [x] The goal is initialized with a velocity with random direction and fixed speed.\n",
    "- [x] The agent must reach the goal in a set time without hitting an obstacle.\n",
    "- [x] The agent can have 1 of 2 fixed speeds, 0.5 pixels/timestep or 1 pixel/timestep.\n",
    "- [x] At each timestep the agent has the choice of 8 actions. These actions indicate one of 8 equally spaced angles and a constant speed.\n",
    "- [x] The goal also reflects off world boundaries, like in billards.\n",
    "- [x] The environment has configurable height and width.\n",
    "- [x] The environment is divided into obstacle lanes which span the environment horizontally.\n",
    "- [x] At the beginning of each episode, the lanes are randomly assigned to carry 1 of 5 classes of obstacles and a direction of movement (left to right or right to left). \n",
    "- [x] Each obstacle class is parameterized by a color and a distribution which describes average obstacle speed and length. \n",
    "- [x] Obstacles maintain a constant speed after entering the environment, pass through the edges of the environment, and are deleted after their entire body exits the observable space.\n",
    "- [x] The number of obstacles introduced into the environment at each timestep is controlled by a Poisson distribution, configured by the level parameter.\n",
    "- [x] Encode the environment in a VAE-readable state.\n",
    "- [x] Make an encoder which reads this environment and compresses it to a continuous 36-vector to mimic the discrete 6x6x1 Z-representation.\n",
    "- [x] Make dataset of X values (flattened current frame) and y values (flattened next frame).\n",
    "- [x] Train the model.\n",
    "- [x] Make goal bounce off walls correctly\n",
    "- [x] https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "- [x] Make obstacles come in and out correctly\n",
    "- [x] https://www.youtube.com/watch?v=lvoHnicueoE\n",
    "- [ ] Make X able to have 800k frames\n",
    "- [x] Make simple autoencoder component\n",
    "- [x] Make simple predictive component\n",
    "- [ ] Make simple decision-making component\n",
    "- [x] Stop the notebook from making a None file\n",
    "- [ ] https://int8.io/monte-carlo-tree-search-beginners-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import random\n",
    "from math import sqrt\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "from math import ceil\n",
    "\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.signal import medfilt\n",
    "from torch import autograd, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Environment\n",
    "\n",
    "We first make the environment.\n",
    "These are some, but not all, of the parts I need to finish to make the environment.\n",
    "\n",
    "At first, the agent will be a simple VAE.\n",
    "\n",
    "I want the `Environment` class to be completely deterministic, assuming that the model is deterministic.\n",
    "The randomness, like for placing the goal and agent, are separated into other functions.\n",
    "We also create an enum to keep track of whether the current game is running, has been won, or has been lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(nested):\n",
    "    values = []\n",
    "    for element in nested:\n",
    "        try:\n",
    "            values = values.concat(flatten(element))\n",
    "        except:\n",
    "            values.append(element)\n",
    "    return values\n",
    "                    \n",
    "def sgn(val):\n",
    "    if val > 0:\n",
    "        return 1\n",
    "    elif val == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "class Vector2D:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __add__(self, v):\n",
    "        return Vector2D(self.x + v.x, self.y + v.y)\n",
    "    \n",
    "    def __mul__(self, a):\n",
    "        return Vector2D(a * self.x, a * self.y)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(type(self).__name__, self.x, self.y)\n",
    "    \n",
    "    def __eq__(self, v):\n",
    "        return self.x == v.x and self.y == v.y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield self.x\n",
    "        yield self.y\n",
    "\n",
    "class Position(Vector2D): \n",
    "    pass\n",
    "\n",
    "class Velocity(Vector2D): \n",
    "    pass\n",
    "        \n",
    "def random_position(height, width):\n",
    "    \"\"\"Generates a psuedorandom position where 0 <= x < height and 0 <= y < width. The x and y are integers.\"\"\"\n",
    "    return Position(random.randrange(height), random.randrange(width))\n",
    "\n",
    "def random_velocity(speed):\n",
    "    theta = random.uniform(-1, 1) * math.pi\n",
    "    return Velocity(speed * math.cos(theta), speed * math.sin(theta))\n",
    "\n",
    "class GameState(Enum):\n",
    "    ONGOING = 0\n",
    "    WON = 1\n",
    "    COLLIDED = 2\n",
    "    TIMEOUT = 3\n",
    "    \n",
    "class Direction(Enum):\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    \n",
    "ObstacleClass = namedtuple('ObstacleClass', ['length', 'speed'])\n",
    "Obstacle = namedtuple('Obstacle', ['obstacle_class', 'position'])\n",
    "\n",
    "def obstacle_from_class_id(id):\n",
    "    \"\"\"The `id` argument is the class ID in [0, 1, 2, 3, 4].\"\"\"\n",
    "    obstacle_classes = [\n",
    "        ObstacleClass(3, 1),\n",
    "        ObstacleClass(3, 2),\n",
    "        ObstacleClass(6, 1),\n",
    "        ObstacleClass(6, 2),\n",
    "        ObstacleClass(1.5, 0.5),\n",
    "    ]\n",
    "    return obstacle_classes[id]\n",
    "\n",
    "def random_obstacle_lanes(n_lanes):\n",
    "    return [obstacle_from_class_id(random.randrange(5)) for _ in range(n_lanes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make the `Environment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_decision():\n",
    "    \"\"\"Get the model's decision on where to move given the current environment using integers 0 through 7.\n",
    "    This is redefined after the model is created.\"\"\"\n",
    "    # until I replicate the model, it will always select action 0\n",
    "    return 0\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, height, width, goal_pos, goal_vel, max_time, level):\n",
    "        \"\"\"\n",
    "            Initialize the environment.\n",
    "            \n",
    "            Args:\n",
    "                height: int, the height of the environment.\n",
    "                width: int, the width of the environment.\n",
    "                goal_pos: Position, the initial position of the goal; the goal is 2x2, so the goal_pos is its bottom-left corner.\n",
    "                goal_vel: Velocity, the velocity of the goal at the start of the experiment. This can change if it hits a wall.\n",
    "                max_time: int, the maximum number of timesteps which can elapse before an automatic loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        assert 0 <= goal_pos.x <= width - 1\n",
    "        assert 0 <= goal_pos.y <= height - 1  # ditto\n",
    "        self.goal_pos = goal_pos\n",
    "\n",
    "        self.goal_vel = goal_vel\n",
    "        \n",
    "        self.max_time = max_time\n",
    "        self.time = 0\n",
    "        \n",
    "        # randomly assign obstacle lanes for each lane.\n",
    "        # note that a single lane can have multiple obstacles, so we have a list of obstacles in each lane\n",
    "        n_obstacle_lanes = self.height\n",
    "        self.n_obstacle_lanes = n_obstacle_lanes\n",
    "        self.obstacle_classes = random_obstacle_lanes(n_obstacle_lanes)\n",
    "        self.obstacle_directions = [Direction(random.randrange(2)) for _ in range(n_obstacle_lanes)]\n",
    "        self.obstacle_lanes = [[] for _ in range(n_obstacle_lanes)]\n",
    "        \n",
    "        self.level = level\n",
    "        self.add_obstacles()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Environment(height={}, width={}, agent_pos={}, goal_pos={}, agent_speed={}, goal_vel={})'.format(\n",
    "            self.height, self.width, self.agent_pos, self.goal_pos, self.agent_speed, self.goal_vel)\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"An ASCII diagram of the environment.\"\"\"\n",
    "\n",
    "        board = '|' + '-' * self.width + '|\\n'\n",
    "        for row in range(self.height):\n",
    "            board += '|'\n",
    "            for col in range(self.width):\n",
    "                if Position(row, col) == self.rounded(self.agent_pos):\n",
    "                    board += 'a'\n",
    "                elif Position(row, col) in self.hitbox(self.goal_pos, (2, 2)):\n",
    "                    board += 'g'\n",
    "                else:\n",
    "                    board += ' '\n",
    "            board += '|\\n'\n",
    "        board += '|' + '-' * self.width + '|'\n",
    "        \n",
    "        return board\n",
    "    \n",
    "    def move(self):\n",
    "        \"\"\"Makes all the objects move in a single timestep and returns the game state.\"\"\"\n",
    "        \n",
    "        def move_object(obj, vel):\n",
    "            # instead of making a good solution, I made an easy one.\n",
    "            # we move the object by velocity * dt where dt is a small scalar.\n",
    "            # if we go out of bounds, then we flip the coordinate(s) which are out of bounds\n",
    "            dt = 0.01\n",
    "            for _ in range(int(1 / dt)):\n",
    "                obj += vel * dt\n",
    "                \n",
    "                if obj.x < 0:\n",
    "                    vel.x = abs(vel.x) * 1  # make sure to go right\n",
    "                elif obj.x > self.width:\n",
    "                    vel.x = abs(vel.x) * -1  # make sure to go left\n",
    "                    \n",
    "                if obj.y < 0:\n",
    "                    vel.y = abs(vel.y) * 1  # make sure to go up\n",
    "                elif obj.y > self.height:\n",
    "                    vel.y = abs(vel.y) * -1  # make sure to go down\n",
    "\n",
    "            \n",
    "            return obj\n",
    "        \n",
    "        self.goal_pos = move_object(self.goal_pos, self.goal_vel)\n",
    "\n",
    "        # we move the obstacles\n",
    "        for lane, direction in zip(self.obstacle_lanes, self.obstacle_directions):\n",
    "            for j, obstacle in enumerate(lane):\n",
    "                speed     = obstacle.obstacle_class.speed\n",
    "                direction = 1 if direction == Direction.RIGHT else -1\n",
    "                obstacle.position.y += direction * speed\n",
    "\n",
    "        self.remove_out_of_bounds_obstacles()\n",
    "        self.add_obstacles()\n",
    "        \n",
    "        self.time += 1\n",
    "\n",
    "    def hitbox(self, position, shape: [int, int]):\n",
    "        \"\"\"\n",
    "        Returns an array of all the positions which are in this element's hitbox.\n",
    "        Note that shape = [length in x, height in y].\n",
    "        \"\"\"\n",
    "        \n",
    "        position = self.rounded(position)\n",
    "        hitboxes = []\n",
    "        for offset_y in range(ceil(shape[0])):\n",
    "            for offset_x in range(ceil(shape[1])):\n",
    "                hitboxes.append(Position(position.x + offset_x, position.y + offset_y))\n",
    "        return hitboxes\n",
    "\n",
    "    def rounded(self, position):\n",
    "        return Position(round(position.x), round(position.y))\n",
    "    \n",
    "    def add_obstacles(self):\n",
    "        \"\"\"Add obstacles based on a Poisson distribution.\"\"\"\n",
    "        \n",
    "        # decide into which lanes to add obstacles\n",
    "        number_obstacles_to_introduce = np.random.poisson(lam=self.level)\n",
    "        obstacle_lanes = list(range(self.n_obstacle_lanes))\n",
    "        random.shuffle(obstacle_lanes)\n",
    "        lanes_in_which_we_add_obstacles = obstacle_lanes[:number_obstacles_to_introduce]\n",
    "        \n",
    "        for lane in lanes_in_which_we_add_obstacles:\n",
    "            end = 0 if self.obstacle_directions[lane] == Direction.RIGHT else self.width\n",
    "            obstacle = Obstacle(self.obstacle_classes[lane], Position(lane, end))\n",
    "            self.obstacle_lanes[lane].append(obstacle)\n",
    "        \n",
    "    def remove_out_of_bounds_obstacles(self):\n",
    "        for lane, direction in zip(self.obstacle_lanes, self.obstacle_directions):\n",
    "            for j, obstacle in enumerate(lane):\n",
    "                left_moving_and_out_of_bounds = direction == Direction.LEFT and obstacle.position.x + obstacle.obstacle_class.length < 0\n",
    "                right_moving_and_out_of_bounds = direction == Direction.RIGHT and obstacle.position.x + obstacle.obstacle_class.length > self.width\n",
    "                \n",
    "                if left_moving_and_out_of_bounds or right_moving_and_out_of_bounds:\n",
    "                    lane.pop(j)\n",
    "\n",
    "    def model_readable_representation(self):\n",
    "        \"\"\"Represents the environment using a torch tensor. A point is 0 if empty, 1 if an obstacle is there, and 2 for goal.\"\"\"\n",
    "        \n",
    "        # we have to increment because (self.width, self.height) is a valid point on the board\n",
    "        rep = np.zeros([self.width+1, self.height+1], dtype=np.float64)\n",
    "        \n",
    "        obstacles = []\n",
    "        for lane in self.obstacle_lanes:\n",
    "            for obstacle in lane:\n",
    "                obstacles.append(obstacle)\n",
    "        obstacle_points = []\n",
    "        for obstacle in obstacles:\n",
    "            for point in environment.hitbox(obstacle.position, [obstacle.obstacle_class.length, 1]):\n",
    "                obstacle_points.append(point)\n",
    "        \n",
    "        for position in obstacle_points:\n",
    "            # obstacles can sometimes go beyond the bounds along the x-axis, \n",
    "            # which is valid but makes it impossible to put them on the representation.\n",
    "            if 0 <= position.x <= self.width and 0 <= position.y <= self.height:\n",
    "                rep[position.x][position.y] = 1\n",
    "\n",
    "        goal_hitpoints = self.hitbox(self.goal_pos, [2, 1])\n",
    "        for position in goal_hitpoints:\n",
    "            if 0 <= position.x < self.width and 0 <= position.y <= self.height:\n",
    "                rep[position.x][position.y] = 2\n",
    "        \n",
    "        return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make an environment and see what it looks like when it's run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 45\n",
    "width = 45\n",
    "max_time = 407\n",
    "goal_speed = 1\n",
    "goal_pos = random_position(height-1, width-1)\n",
    "goal_vel = random_velocity(goal_speed)\n",
    "level = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "environment = Environment(height, width, goal_pos, goal_vel, max_time, level)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, height), ylim=(0, width))\n",
    "a = np.random.random((height, width))\n",
    "cmap = LinearSegmentedColormap.from_list('mycmap', ['purple'])\n",
    "im = plt.imshow(a, interpolation='none', cmap='plasma')\n",
    "\n",
    "def animate(i):\n",
    "    frame = environment.model_readable_representation()\n",
    "    a = im.get_array()\n",
    "    a = frame\n",
    "    im.set_array(a)\n",
    "    environment.move()\n",
    "\n",
    "    return [im]\n",
    "    \n",
    "animation = matplotlib.animation.FuncAnimation(fig, animate, frames=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate a dataset of frames, which we call $X$. It can take a long time to make the dataset, so we prefer to save and reload it.\n",
    "Note that the computer might not be able to hold all 800,000 frames in memory at once; my laptop can only hold 500,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_data_points = 1000  # they used about 800,000 in the original paper\n",
    "\n",
    "try:\n",
    "    X = np.load('autoencoder-data.npy')\n",
    "    if len(X) > n_data_points:\n",
    "        X = X[:n_data_points]\n",
    "    elif len(X) < n_data_points:\n",
    "        # we have to make more\n",
    "        raise ValueError('insufficiently-many frames in dataset.')\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    if isinstance(e, FileNotFoundError):\n",
    "        # if we couldn't load the file, then we need to make an entire dataset from scratch\n",
    "        X = np.zeros((n_data_points, (height + 1) * (width + 1)), dtype=np.float32)\n",
    "        n_data_points_collected = 0\n",
    "    else:\n",
    "        # we extend the old X to have enough space for the new dataset\n",
    "        old_X = X\n",
    "        X = np.zeros((n_data_points, (height + 1) * (width + 1)), dtype=np.float32)\n",
    "        for i, frame in enumerate(old_X):\n",
    "            X[i] = frame\n",
    "        n_data_points_collected = len(old_X)\n",
    "\n",
    "    while n_data_points_collected < n_data_points:\n",
    "        environment = Environment(height, width, agent_pos, goal_pos, agent_speed, goal_vel, max_time, level)\n",
    "        rep = environment.model_readable_representation().flatten()\n",
    "        X[n_data_points_collected] = rep\n",
    "        n_data_points_collected += 1\n",
    "        while n_data_points_collected < n_data_points:\n",
    "            X[n_data_points_collected] = environment.model_readable_representation().flatten()\n",
    "            environment.move()\n",
    "            n_data_points_collected += 1\n",
    "    np.save('autoencoder-data.npy', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Planning Model\n",
    "\n",
    "The environmental model takes in 5 states of the environment and predicts the next state.\n",
    "\n",
    "![Model Overview](figs/model-overview.png)\n",
    "\n",
    "There are 2 components of this model:\n",
    "\n",
    "- an autoencoder which converts a frame to a representation\n",
    "- a predictive model which predicts the next frame's representation.\n",
    "\n",
    "We first make and train the first component, and then the second.\n",
    "In the final model, the predictive model actually takes 5 consecutive frames' representations, but that's a minor detail we'll add later.\n",
    "We note that both the autoencoder and the predictive model are trained in a supervised manner.\n",
    "\n",
    "We first define the hyperparameters.\n",
    "We use a `Z_dim` of 36 because the final model will use a 6x6x1 Z-representation instead of a continuous real vector.\n",
    "We set `h_dim` to 200 because it seems like a good number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = (width + 1) * (height + 1)\n",
    "h_dim = 200\n",
    "Z_dim = 36\n",
    "lr = 0.001\n",
    "n_train_epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make the model itself, which is a simple encoder-decoder model.\n",
    "\n",
    "We use Xavier initialization for the weights.\n",
    "The encoder is a 1-hidden-layer feed forward neural network, and the decoder is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    input_dim = size[0]\n",
    "    xavier_stdev = 1 / np.sqrt(input_dim / 2)\n",
    "    return Variable(torch.randn(*size) * xavier_stdev, requires_grad=True)\n",
    "\n",
    "\n",
    "Wxh = xavier_init(size=[x_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "Whh = xavier_init(size=[h_dim, h_dim])\n",
    "bhh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whz_mu = xavier_init(size=[h_dim, Z_dim])\n",
    "bhz_mu = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "Whz_var = xavier_init(size=[h_dim, Z_dim])\n",
    "bhz_var = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def Q(x):\n",
    "    x = x.float()  # correct type and shape\n",
    "    \n",
    "    # the model expects the input to have shape [batch size, width+1, height+1], which is then flattened.\n",
    "\n",
    "    if x.shape == (width+1, height+1):\n",
    "        x = x.reshape([1, (width+1)*(height+1)])\n",
    "    \n",
    "    h = nn.relu(x @ Wxh + bxh)\n",
    "    h = nn.relu(h @ Whh + bhh)\n",
    "    z_mu = h @ Whz_mu + bhz_mu\n",
    "    z_var = h @ Whz_var + bhz_var\n",
    "    max_z_var = 87.\n",
    "    # we have to keep the variance within a reasonable bound\n",
    "    # because we take the exponent of it when we find the loss,\n",
    "    # and it overflows past max_z_var\n",
    "    z_var = torch.clamp(z_var, min=-max_z_var, max=max_z_var)\n",
    "    return z_mu, z_var\n",
    "\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = Variable(torch.randn(batch_size, Z_dim))\n",
    "    return mu + torch.exp(log_var / 2) * eps\n",
    "\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, x_dim])\n",
    "bhx = Variable(torch.zeros(x_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def P(z):\n",
    "    h = nn.relu(z @ Wzh + bzh)\n",
    "    x = torch.sigmoid(h @ Whx + bhx)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_data_points = 5000  # they used about 800,000 in the original paper\n",
    "\n",
    "try:\n",
    "    X = np.load('autoencoder-data.npy')\n",
    "    if len(X) > n_data_points:\n",
    "        X = X[:n_data_points]\n",
    "    elif len(X) < n_data_points:\n",
    "        # we have to make more\n",
    "        raise ValueError('insufficiently-many frames in dataset.')\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    if isinstance(e, FileNotFoundError):\n",
    "        # if we couldn't load the file, then we need to make an entire dataset from scratch\n",
    "        X = np.zeros((n_data_points, (height + 1) * (width + 1)), dtype=np.float32)\n",
    "        n_data_points_collected = 0\n",
    "    else:\n",
    "        # we extend the old X to have enough space for the new dataset\n",
    "        old_X = X\n",
    "        X = np.zeros((n_data_points, (height + 1) * (width + 1)), dtype=np.float32)\n",
    "        for i, frame in enumerate(old_X):\n",
    "            X[i] = frame\n",
    "        n_data_points_collected = len(old_X)\n",
    "\n",
    "    while n_data_points_collected < n_data_points:\n",
    "        environment = Environment(height, width, agent_pos, goal_pos, agent_speed, goal_vel, max_time, level)\n",
    "        rep = environment.model_readable_representation().flatten()\n",
    "        X[n_data_points_collected] = rep\n",
    "        n_data_points_collected += 1\n",
    "        while n_data_points_collected < n_data_points:\n",
    "            rep = environment.model_readable_representation().flatten()\n",
    "            X[n_data_points_collected] = rep\n",
    "            environment.move()\n",
    "            n_data_points_collected += 1\n",
    "    np.save('autoencoder-data.npy', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the autoencoder now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [Wxh, Whh, bhh, bxh, Whz_mu, bhz_mu, Whz_var, bhz_var, Wzh, bzh, Whx, bhx]\n",
    "\n",
    "solver = optim.Adam(params, lr=lr)\n",
    "losses = []\n",
    "losses_in_epoch = []\n",
    "losses_avg_per_epoch = []\n",
    "\n",
    "X_torch = torch.from_numpy(X)\n",
    "\n",
    "for epoch in range(n_train_epochs):\n",
    "    print('Beginning epoch {}'.format(epoch))\n",
    "    shuffled_indices = torch.randperm(len(X))\n",
    "    batches_indices = []\n",
    "    batch_indices = []\n",
    "    for index in shuffled_indices:\n",
    "        batch_indices.append(index)\n",
    "        if len(batch_indices) == batch_size:\n",
    "            batches_indices.append(batch_indices)\n",
    "            batch_indices = []\n",
    "            \n",
    "    losses_in_epoch = []\n",
    "    for batch_indices in batches_indices:\n",
    "        batch = Variable(X_torch[batch_indices])\n",
    "        y_true = Variable(X_torch[batch_indices])\n",
    "        \n",
    "        # Forward\n",
    "        z_mu, z_var = Q(batch)\n",
    "        z = sample_z(z_mu, z_var)\n",
    "        y_pred = P(z)\n",
    "\n",
    "        # Loss\n",
    "        recon_loss = nn.binary_cross_entropy(y_pred, y_true, reduction='sum') / batch_size\n",
    "        kl_loss = torch.mean(0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1. - z_var, 1))\n",
    "        loss = recon_loss + kl_loss\n",
    "        \n",
    "        losses.append(loss)\n",
    "        losses_in_epoch.append(loss)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        solver.step()\n",
    "        \n",
    "    losses_avg_per_epoch.append(sum(losses_in_epoch) / len(batch_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(medfilt(losses))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(frame):\n",
    "    \"\"\"Accepts a numpy ndarray.\"\"\"\n",
    "    frame = torch.from_numpy(frame)\n",
    "    return Q(frame)\n",
    "\n",
    "\n",
    "def decode(representation):\n",
    "    frames_generated = P(sample_z(*representation)).reshape(batch_size, height+1, width+1)\n",
    "    frame = frames_generated[0]\n",
    "    frame = np.float64(frame.detach().numpy())\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the model's predicted next frame with the actual next frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(height, width, goal_pos, goal_vel, max_time, level)\n",
    "\n",
    "frame = environment.model_readable_representation()\n",
    "reconstruction = decode(encode(frame))\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('mycmap', ['purple', 'yellow', 'blue'])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "plt.title('Original Frame')\n",
    "plt.imshow(frame, cmap=cmap)\n",
    "plt.subplot(222)\n",
    "plt.title('Reconstruction')\n",
    "plt.imshow(reconstruction, cmap=cmap)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make the next-frame-predictor.\n",
    "It takes the current frame's representation and predicts the next frame's representation.\n",
    "We generate its training set by running the autoencoder on every frame, which is very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_of_all_frames_z_mu, representations_of_all_frames_z_var = encode(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can train on the X representions.\n",
    "For now, the model will be a simple neural network, not a gated CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_future_n_train_epochs = 10\n",
    "predict_future_lr = 0.01\n",
    "predict_future_batch_size = 100\n",
    "predict_future_h_dim = 50\n",
    "predict_future_Wxh_z_mu = Variable(torch.zeros(Z_dim, predict_future_h_dim), requires_grad=True)\n",
    "predict_future_bxh_z_mu = Variable(torch.zeros(predict_future_h_dim), requires_grad=True)\n",
    "predict_future_Whx_z_mu = Variable(torch.zeros(predict_future_h_dim, Z_dim), requires_grad=True)\n",
    "predict_future_bhx_z_mu = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "predict_future_trainable_params_z_mu = [predict_future_Wxh_z_mu, predict_future_bxh_z_mu]\n",
    "solver = optim.Adam(predict_future_trainable_params_z_mu, lr=predict_future_lr)\n",
    "\n",
    "def predict_future_z_mu(current_representation):\n",
    "    \"\"\"\n",
    "    Predicts the next frame's VAE representation.\n",
    "    For now, it just uses a single frame, but it will eventually use many previous frames.\n",
    "    Args:\n",
    "        current_representation: torch.Variable, should have shape [batch_size, Z_dim].\n",
    "    Returns:\n",
    "        The Z representation of the next frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    h = nn.relu(current_representation @ predict_future_Wxh_z_mu + predict_future_bxh_z_mu)\n",
    "    future_representation = nn.relu(h @ predict_future_Whx_z_mu + predict_future_bhx_z_mu)\n",
    "    return future_representation\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(predict_future_n_train_epochs):\n",
    "    print('Beginning epoch', epoch)\n",
    "    shuffled_indices = torch.randperm(len(representations_of_all_frames_z_mu)-1)\n",
    "    batches_indices = []\n",
    "    batch_indices = []\n",
    "    for index in shuffled_indices:\n",
    "        batch_indices.append(index)\n",
    "        if len(batch_indices) == predict_future_batch_size:\n",
    "            batches_indices.append(batch_indices)\n",
    "            batch_indices = []\n",
    "           \n",
    "    for batch_indices in batches_indices:\n",
    "        x = Variable(representations_of_all_frames_z_mu[batch_indices])\n",
    "        y_true = Variable(representations_of_all_frames_z_mu[[i + 1 for i in batch_indices]])\n",
    "        \n",
    "        # Forward\n",
    "        y_pred = predict_future_z_mu(x)\n",
    "        \n",
    "        # Loss\n",
    "        loss = nn.binary_cross_entropy(y_pred, y_true, reduction='sum') / predict_future_batch_size\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        solver.step()\n",
    "        \n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_future_n_train_epochs = 10\n",
    "predict_future_lr = 0.01\n",
    "predict_future_batch_size = 100\n",
    "predict_future_h_dim = 50\n",
    "predict_future_Wxh_z_var = Variable(torch.zeros(Z_dim, predict_future_h_dim), requires_grad=True)\n",
    "predict_future_bxh_z_var = Variable(torch.zeros(predict_future_h_dim), requires_grad=True)\n",
    "predict_future_Whx_z_var = Variable(torch.zeros(predict_future_h_dim, Z_dim), requires_grad=True)\n",
    "predict_future_bhx_z_var = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "predict_future_trainable_params_z_var = [predict_future_Wxh_z_var, predict_future_bxh_z_var]\n",
    "solver = optim.Adam(predict_future_trainable_params_z_var, lr=predict_future_lr)\n",
    "\n",
    "def predict_future_z_var(current_representation):\n",
    "    \"\"\"\n",
    "    Predicts the next frame's VAE representation.\n",
    "    For now, it just uses a single frame, but it will eventually use many previous frames.\n",
    "    Args:\n",
    "        current_representation: torch.Variable, should have shape [batch_size, Z_dim].\n",
    "    Returns:\n",
    "        The Z representation of the next frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    h = nn.relu(current_representation @ predict_future_Wxh_z_var + predict_future_bxh_z_var)\n",
    "    future_representation = nn.relu(h @ predict_future_Whx_z_var + predict_future_bhx_z_var)\n",
    "    return future_representation\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(predict_future_n_train_epochs):\n",
    "    print('Beginning epoch', epoch)\n",
    "    shuffled_indices = torch.randperm(len(representations_of_all_frames_z_var)-1)\n",
    "    batches_indices = []\n",
    "    batch_indices = []\n",
    "    for index in shuffled_indices:\n",
    "        batch_indices.append(index)\n",
    "        if len(batch_indices) == predict_future_batch_size:\n",
    "            batches_indices.append(batch_indices)\n",
    "            batch_indices = []\n",
    "           \n",
    "    for batch_indices in batches_indices:\n",
    "        x = Variable(representations_of_all_frames_z_var[batch_indices])\n",
    "        y_true = Variable(representations_of_all_frames_z_var[[i + 1 for i in batch_indices]])\n",
    "        \n",
    "        # Forward\n",
    "        y_pred = predict_future_z_var(x)\n",
    "        \n",
    "        # Loss\n",
    "        loss = nn.binary_cross_entropy(y_pred, y_true, reduction='sum') / predict_future_batch_size\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        solver.step()\n",
    "        \n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(z_mu, z_var):\n",
    "    return predict_future_z_mu(z_mu), predict_future_z_var(z_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these components, we now have a model which predicts the future.\n",
    "For now, we'll just use the actual environment playout because the model is not very accurate yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    frame = decode(predict_future(*encode(frame)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(height, width, goal_pos, goal_vel, max_time, level)\n",
    "\n",
    "environment_prediction = []\n",
    "for _ in range(max_time):\n",
    "    environment_prediction.append(environment.model_readable_representation())\n",
    "    environment.move()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Making Component\n",
    "\n",
    "Now, we use reinforcement learning with a Monte Carlo tree search to decide the direction of movement. \n",
    "The agent can move like a king in chess: up, down, left, right, or a diagonal.\n",
    "From this, each node in the tree search has 8 children.\n",
    "There are 8 moves available at every step, so there are more potential plays than there are atoms in the universe, by several orders of orders of magnitudes.\n",
    "\n",
    "We use an agent mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_mask(agent_pos):\n",
    "    mask = np.zeros((height+1, width+1))\n",
    "    mask[int(agent_pos.x), int(agent_pos.y)] = 3.\n",
    "    return mask\n",
    "\n",
    "\n",
    "def bounce(agent_pos, height, width):\n",
    "    if agent_pos.x < 0:\n",
    "        agent_pos.x = -agent_pos.x\n",
    "    elif agent_pos.x >= width:\n",
    "        agent_pos.x = width - (agent_pos.x + 1 - width)\n",
    "    \n",
    "    if agent_pos.y < 0:\n",
    "        agent_pos.y = -agent_pos.y\n",
    "    elif agent_pos.y >= height:\n",
    "        agent_pos.y = height - (agent_pos.y + 1 - height)\n",
    "        \n",
    "    return agent_pos\n",
    "\n",
    "\n",
    "agent_pos = Position(10, 10)\n",
    "directions = [\n",
    "    Velocity(-1/sqrt(2), 1/sqrt(2)),  Velocity(0, 1),  Velocity(1/sqrt(2), 1/sqrt(2)),\n",
    "    Velocity(-1, 0),                                   Velocity(0, 1),\n",
    "    Velocity(-1/sqrt(2), -1/sqrt(2)), Velocity(0, -1), Velocity(1/sqrt(2), -1/sqrt(2)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(height, width, goal_pos, goal_vel, max_time, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves = [directions[random.randint(0, 7)] for _ in range(max_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(environment_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameplay_frames = []\n",
    "for move, pred in zip(moves, environment_prediction):\n",
    "    agent_pos = bounce(agent_pos + move, height, width)\n",
    "    gameplay_frames.append(agent_mask(agent_pos) + pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "environment = Environment(height, width, goal_pos, goal_vel, max_time, level)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, height), ylim=(0, width))\n",
    "a = np.random.random((height, width))\n",
    "cmap = LinearSegmentedColormap.from_list('mycmap', ['purple'])\n",
    "im = plt.imshow(a, interpolation='none', cmap='plasma')\n",
    "\n",
    "def animate(i):\n",
    "    frame = gameplay_frames[i]\n",
    "    a = im.get_array()\n",
    "    a = frame\n",
    "    im.set_array(a)\n",
    "    environment.move()\n",
    "\n",
    "    return [im]\n",
    "\n",
    "animation = matplotlib.animation.FuncAnimation(fig, animate, frames=max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_pos = Position(0, 0)\n",
    "for move, pred in zip(moves, environment_prediction):\n",
    "    agent_pos = bounce(agent_pos + move, height, width)\n",
    "    print(pred[agent_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
