{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction: Planning in Dynamic Environments with Conditional Autoregressive Models\n",
    "\n",
    "**Abhinav Madahar (<abhinav.madahar@rutgers.edu>) &middot; Sungjin Ahn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from math import sqrt\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Environment\n",
    "\n",
    "We first make the environment.\n",
    "These are some, but not all, of the parts I need to finish to make the environment.\n",
    "\n",
    "- [x] Movement about the environment is continuous, but collision and goal checking is quantized to the nearest pixel.\n",
    "- [x] The agent (controlled by the model) is a $1 \\times 1$ object and the goal is $2 \\times 2$.\n",
    "- [x] Both are randomly placed.\n",
    "- [x] The goal is initialized with a velocity with random direction and fixed speed.\n",
    "- [x] The agent must reach the goal in a set time without hitting an obstacle.\n",
    "- [x] The agent can have 1 of 2 fixed speeds, 0.5 pixels/timestep or 1 pixel/timestep.\n",
    "- [x] At each timestep the agent has the choice of 8 actions. These actions indicate one of 8 equally spaced angles and a constant speed.\n",
    "- [x] The goal also reflects off world boundaries, like in billards.\n",
    "- [x] The environment has configurable height and width.\n",
    "- [ ] The environment is divided into obstacle lanes which span the environment horizontally.\n",
    "- [ ] At the beginning of each episode, the lanes are randomly assigned to carry 1 of 5 classes of obstacles and a direction of movement (left to right or right to left). \n",
    "- [ ] Each obstacle class is parameterized by a color and a distribution which describes average obstacle speed and length. \n",
    "- [ ] Obstacles maintain a constant speed after entering the environment, pass through the edges of the environment, and are deleted after their entire body exits the observable space.\n",
    "- [ ] The number of obstacles introduced into the environment at each timestep is controlled by a Poisson distribution, configured by the level parameter.\n",
    "\n",
    "I want the `Environment` class to be completely deterministic, assuming that the model is deterministic.\n",
    "The randomness, like for placing the goal and agent, are separated into other functions.\n",
    "We also create an enum to keep track of whether the current game is running, has been won, or has been lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vector2D:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __add__(self, v):\n",
    "        return Vector2D(self.x + v.x, self.y + v.y)\n",
    "    \n",
    "    def __mul__(self, a):\n",
    "        return Vector2D(a * self.x, a * self.y)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(type(self).__name__, self.x, self.y)\n",
    "    \n",
    "    def __eq__(self, v):\n",
    "        return self.x == v.x and self.y == v.y\n",
    "\n",
    "class Position(Vector2D): \n",
    "    pass\n",
    "\n",
    "class Velocity(Vector2D): \n",
    "    pass\n",
    "        \n",
    "def random_position(height, width):\n",
    "    \"\"\"Generates a psuedorandom position where 0 <= x < height and 0 <= y < width. The x and y are integers.\"\"\"\n",
    "    return Position(random.randrange(height), random.randrange(width))\n",
    "\n",
    "def random_velocity(speed):\n",
    "    theta = random.uniform(-1, 1) * math.pi\n",
    "    return Velocity(speed * math.cos(theta), speed * math.sin(theta))\n",
    "\n",
    "class GameState(Enum):\n",
    "    ONGOING = 0\n",
    "    WON = 1\n",
    "    COLLIDED = 2\n",
    "    TIMEOUT = 3\n",
    "    \n",
    "class Direction(Enum):\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    \n",
    "ObstacleClass = namedtuple('Obstacle', ['length', 'speed'])\n",
    "\n",
    "def obstacle_from_class_id(id):\n",
    "    \"\"\"The `id` argument is the class ID in [0, 1, 2, 3, 4].\"\"\"\n",
    "    obstacle_classes = [\n",
    "        Obstacle(1, 1),\n",
    "        Obstacle(1, 2),\n",
    "        Obstacle(2, 1),\n",
    "        Obstacle(2, 2),\n",
    "        Obstacle(0.5, 0.5),\n",
    "    ]\n",
    "    return obstacle_classes[id]\n",
    "\n",
    "def random_obstacle_lanes(n_lanes):\n",
    "    return [random.randrange(5) for _ in range(n_lanes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make the `Environment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, height, width, agent_pos, goal_pos, agent_speed, goal_vel, max_time, level):\n",
    "        \"\"\"\n",
    "            Initialize the environment.\n",
    "            \n",
    "            Args:\n",
    "                height: int, the height of the environment.\n",
    "                width: int, the width of the environment.\n",
    "                agent_pos: Position, the initial position of the agent.\n",
    "                goal_pos: Position, the initial position of the goal; the goal is 2x2, so the goal_pos is its bottom-left corner.\n",
    "                agent_speed: float, the speed (not velocity) of the agent. The model controls the direction.\n",
    "                goal_vel: Velocity, the velocity of the goal at the start of the experiment. This can change if it hits a wall.\n",
    "                max_time: int, the maximum number of timesteps which can elapse before an automatic loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        assert 0 <= agent_pos.x <= width\n",
    "        assert 0 <= agent_pos.y <= height\n",
    "        assert 0 <= goal_pos.x <= width - 1\n",
    "        assert 0 <= goal_pos.y <= height - 1  # ditto\n",
    "        self.agent_pos = agent_pos\n",
    "        self.goal_pos = goal_pos\n",
    "\n",
    "        self.agent_speed = agent_speed\n",
    "        self.goal_vel = goal_vel\n",
    "        \n",
    "        self.max_time = max_time\n",
    "        self.time = 0\n",
    "        \n",
    "        # randomly assign obstacle lanes for each lane\n",
    "        # if a lane is None, then \n",
    "        n_obstacle_lanes = self.height\n",
    "        self.n_obstacle_lanes = n_obstacle_lanes\n",
    "        self.obstacle_lane_class_ids = random_obstacle_lanes(n_obstacle_lanes)\n",
    "        self.obstacle_directions = [Direction(random.randrange(2)) for _ in range(n_obstacle_lanes)]\n",
    "        self.obstacle_lanes = [None] * n_obstacle_lanes\n",
    "        \n",
    "        self.level = level\n",
    "        self.add_obstacles()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Environment(height={}, width={}, agent_pos={}, goal_pos={}, agent_speed={}, goal_vel={})'.format(\n",
    "            self.height, self.width, self.agent_pos, self.goal_pos, self.agent_speed, self.goal_vel)\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"An ASCII diagram of the environment.\"\"\"\n",
    "\n",
    "        board = '|' + '-' * self.width + '|\\n'\n",
    "        for row in range(self.height):\n",
    "            board += '|'\n",
    "            for col in range(self.width):\n",
    "                if Position(row, col) == self.rounded(self.agent_pos):\n",
    "                    board += 'a'\n",
    "                elif Position(row, col) in self.hitbox(self.goal_pos, (2, 2)):\n",
    "                    board += 'g'\n",
    "                else:\n",
    "                    board += ' '\n",
    "            board += '|\\n'\n",
    "        board += '|' + '-' * self.width + '|'\n",
    "        \n",
    "        return board\n",
    "    \n",
    "    def move(self):\n",
    "        \"\"\"Makes all the objects move in a single timestep and returns the game state.\"\"\"\n",
    "        \n",
    "        def move_object(obj, vel):\n",
    "            if (obj + vel).x > self.width:\n",
    "                t = (self.width - obj.x) / vel.x\n",
    "                obj += vel * t\n",
    "                vel.x = -vel.x  # the agent bounces off the wall, so it flips its x movement\n",
    "\n",
    "            if (obj + vel).y > self.height:\n",
    "                t = (self.width - obj.y) / vel.y\n",
    "                obj += vel * t\n",
    "                vel.y = -vel.y\n",
    "                obj += vel * (1-t)\n",
    "\n",
    "            else:\n",
    "                obj += vel\n",
    "            \n",
    "            return obj\n",
    "        \n",
    "        self.agent_pos = move_object(self.agent_pos, self.model_decision())\n",
    "        self.goal_pos = move_object(self.goal_pos, self.goal_vel)\n",
    "\n",
    "        self.time += 1\n",
    "        \n",
    "        if self.rounded(self.agent_pos) in self.hitbox(self.goal_pos, [2, 2]):\n",
    "            return GameState.WON\n",
    "        \n",
    "        if self.time >= self.max_time:\n",
    "            return GameState.TIMEOUT\n",
    "        \n",
    "        return GameState.ONGOING\n",
    "\n",
    "    def hitbox(self, position, shape: [int, int]):\n",
    "        \"\"\"\n",
    "        Returns an array of all the positions which are in this element's hitbox.\n",
    "        Note that shape = [length in x, height in y].\n",
    "        \"\"\"\n",
    "        \n",
    "        position = self.rounded(position)\n",
    "        x = position.x\n",
    "        y = position.y\n",
    "        return [Position(x + offset_x, y + offset_y) for offset_x in range(shape[0]) for offset_y in range(shape[0])]\n",
    "\n",
    "    def rounded(self, position):\n",
    "        return Position(round(position.x), round(position.y))\n",
    "    \n",
    "    def model_decision(self):\n",
    "        \"\"\"Get the model's decision on where to move given the current environment using integers 0 through 7.\"\"\"\n",
    "        # until I replicate the model, it will always select action 0\n",
    "        decision = 0\n",
    "        decisions = [\n",
    "            Velocity(-1/sqrt(2), 1/sqrt(2)),  Velocity(0, 1),  Velocity(-1/sqrt(2), -1/sqrt(2)),\n",
    "            Velocity(-1, 0),                                   Velocity(0, 1),\n",
    "            Velocity(-1/sqrt(2), -1/sqrt(2)), Velocity(0, -1), Velocity(-1/sqrt(2), -1/sqrt(2)),\n",
    "        ]\n",
    "        return decisions[decision] * self.agent_speed\n",
    "    \n",
    "    def add_obstacles(self):\n",
    "        \"\"\"Add obstacles based on a Poisson distribution.\"\"\"\n",
    "        number_obstacles_to_introduce = np.random.poisson(lam=self.level)\n",
    "        obstacle_lanes = list(range(self.n_obstacle_lanes))\n",
    "        random.shuffle(obstacle_lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 45\n",
    "width = 45\n",
    "max_time = 10\n",
    "goal_speed = 407\n",
    "agent_pos = random_position(height, width)\n",
    "goal_pos = random_position(height-1, width-1)\n",
    "agent_speed = 1\n",
    "goal_vel = random_velocity(goal_speed)\n",
    "level = 6\n",
    "environment = Environment(height, width, agent_pos, goal_pos, agent_speed, goal_vel, max_time, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.obstacle_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
